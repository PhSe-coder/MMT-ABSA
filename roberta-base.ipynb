{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import MyDataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", model_max_length=100)\n",
    "train_dataset = MyDataset(\"./data/laptop.train.txt\", tokenizer)\n",
    "eval_dataset = MyDataset(\"./dataset/rest.validation.txt\", tokenizer)\n",
    "test_dataset = MyDataset(\"./dataset/rest.test.txt\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "TAGS = ['O', 'B-POS', 'B-NEG', 'B-NEU', 'I-POS', 'I-NEG', 'I-NEU']\n",
    "def id2label(predict: List[List[int]], gold: List[List[int]]):\n",
    "    gold_Y: List[List[str]] = []\n",
    "    pred_Y: List[List[str]] = []\n",
    "    for _pred, _gold in zip(predict, gold):\n",
    "        assert len(_gold) == len(_pred)\n",
    "        gold_list = [TAGS[_gold[i]] for i in range(len(_gold)) if _gold[i] != -1]\n",
    "        pred_list = [TAGS[_pred[i]] for i in range(len(_gold)) if _gold[i] != -1]\n",
    "        gold_Y.append(gold_list)\n",
    "        pred_Y.append(pred_list)\n",
    "    return pred_Y, gold_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3045\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 573\n",
      "/home/oyf/anaconda3/envs/bert-uda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [573/573 03:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Micro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.460296</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.190703</td>\n",
       "      <td>0.296567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.525376</td>\n",
       "      <td>0.679654</td>\n",
       "      <td>0.187128</td>\n",
       "      <td>0.293455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.519360</td>\n",
       "      <td>0.640741</td>\n",
       "      <td>0.206198</td>\n",
       "      <td>0.311989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 776\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 776\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "/home/oyf/anaconda3/envs/bert-uda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 776\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2158\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[[ 7.20796585e+00,  6.59066558e-01, -1.83504248e+00, ...,\n",
       "         -6.97364092e-01, -2.06241584e+00, -1.81653881e+00],\n",
       "        [ 7.48648262e+00,  5.38699746e-01, -1.99433732e+00, ...,\n",
       "         -7.19753623e-01, -2.10051537e+00, -1.78098714e+00],\n",
       "        [ 5.40427065e+00,  2.76849008e+00, -1.15224111e+00, ...,\n",
       "         -3.86806130e-01, -2.56797552e+00, -2.19729066e+00],\n",
       "        ...,\n",
       "        [ 6.79556179e+00,  8.88111115e-01, -1.95088303e+00, ...,\n",
       "         -6.63545251e-01, -2.01610208e+00, -1.69472635e+00],\n",
       "        [ 7.08384418e+00,  6.76379383e-01, -1.98597538e+00, ...,\n",
       "         -7.13197708e-01, -2.00047469e+00, -1.70323718e+00],\n",
       "        [ 6.83704758e+00,  8.26546550e-01, -1.97394776e+00, ...,\n",
       "         -6.80289209e-01, -2.00996804e+00, -1.67529786e+00]],\n",
       "\n",
       "       [[ 7.39760780e+00, -4.21143621e-01, -1.81070447e+00, ...,\n",
       "         -8.17592800e-01, -1.46576190e+00, -1.38333344e+00],\n",
       "        [ 8.15382481e+00, -9.67814684e-01, -2.03173470e+00, ...,\n",
       "         -9.08089042e-01, -1.59430480e+00, -1.42941463e+00],\n",
       "        [ 8.13989067e+00, -9.84240532e-01, -2.03265166e+00, ...,\n",
       "         -9.76115108e-01, -1.53482914e+00, -1.36411250e+00],\n",
       "        ...,\n",
       "        [ 6.58316088e+00, -3.56132954e-01, -2.27055359e+00, ...,\n",
       "          5.04721776e-02, -1.20363903e+00, -1.03428066e+00],\n",
       "        [ 7.42261600e+00, -5.03373981e-01, -2.01449060e+00, ...,\n",
       "         -6.58470511e-01, -1.54186988e+00, -1.12739813e+00],\n",
       "        [ 7.33221531e+00, -1.10576235e-01, -1.81770241e+00, ...,\n",
       "         -9.64468598e-01, -1.70698690e+00, -1.26555181e+00]],\n",
       "\n",
       "       [[ 7.25582457e+00,  4.18410987e-01, -1.74680769e+00, ...,\n",
       "         -8.44628692e-01, -1.98520041e+00, -1.69050133e+00],\n",
       "        [ 6.79649544e+00,  1.55728734e+00, -1.58397675e+00, ...,\n",
       "         -8.69899035e-01, -2.50500131e+00, -2.25101113e+00],\n",
       "        [ 7.95596170e+00, -5.76337148e-03, -1.96889675e+00, ...,\n",
       "         -9.29922581e-01, -2.07918954e+00, -1.77965152e+00],\n",
       "        ...,\n",
       "        [ 7.14008713e+00,  2.14518353e-01, -1.89876032e+00, ...,\n",
       "         -9.01631296e-01, -1.93974996e+00, -1.70152462e+00],\n",
       "        [ 7.12719011e+00,  2.25178480e-01, -1.88882208e+00, ...,\n",
       "         -9.09190416e-01, -1.93583667e+00, -1.72674477e+00],\n",
       "        [ 7.06379223e+00,  2.63409257e-01, -1.88862014e+00, ...,\n",
       "         -9.11928535e-01, -1.94492710e+00, -1.71636236e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 7.81800413e+00, -9.63015318e-01, -1.46340787e+00, ...,\n",
       "         -1.46528101e+00, -1.35233235e+00, -1.52834249e+00],\n",
       "        [ 8.34563065e+00, -1.18917978e+00, -1.69713986e+00, ...,\n",
       "         -1.26802218e+00, -1.40160203e+00, -1.66276252e+00],\n",
       "        [ 8.34874249e+00, -9.86523509e-01, -1.62841058e+00, ...,\n",
       "         -1.36009085e+00, -1.45767570e+00, -1.70822632e+00],\n",
       "        ...,\n",
       "        [ 3.99582410e+00, -1.01665127e+00, -1.72844195e+00, ...,\n",
       "         -1.04705952e-01, -4.60694611e-01, -6.63542897e-02],\n",
       "        [ 6.92082024e+00, -8.96274388e-01, -1.90318346e+00, ...,\n",
       "         -9.57029581e-01, -9.44201827e-01, -1.01789367e+00],\n",
       "        [ 8.13152313e+00, -1.08788812e+00, -1.74828792e+00, ...,\n",
       "         -1.45962417e+00, -1.34227312e+00, -1.58880568e+00]],\n",
       "\n",
       "       [[ 7.62959957e+00,  4.13169041e-02, -1.68587101e+00, ...,\n",
       "         -1.05373681e+00, -1.80092859e+00, -1.82055986e+00],\n",
       "        [ 8.26170540e+00, -6.17055357e-01, -1.83280945e+00, ...,\n",
       "         -1.21329236e+00, -1.86229110e+00, -1.61896408e+00],\n",
       "        [ 8.31604385e+00, -6.08335972e-01, -1.86362851e+00, ...,\n",
       "         -1.11085320e+00, -1.69086802e+00, -1.70208514e+00],\n",
       "        ...,\n",
       "        [ 8.09681702e+00, -2.46210977e-01, -1.88778663e+00, ...,\n",
       "         -1.14904690e+00, -1.87225831e+00, -1.81638598e+00],\n",
       "        [ 7.74816179e+00, -5.07543348e-02, -1.90904379e+00, ...,\n",
       "         -1.23703551e+00, -1.78030503e+00, -1.72919154e+00],\n",
       "        [ 7.59010267e+00,  6.61803111e-02, -1.85743630e+00, ...,\n",
       "         -1.22982574e+00, -1.84580564e+00, -1.74246991e+00]],\n",
       "\n",
       "       [[ 7.75622177e+00, -2.30605826e-01, -1.44061184e+00, ...,\n",
       "         -1.25948846e+00, -1.61860955e+00, -1.83079636e+00],\n",
       "        [ 8.29776764e+00, -7.25263834e-01, -1.74867201e+00, ...,\n",
       "         -1.29381680e+00, -1.67883277e+00, -1.77197337e+00],\n",
       "        [ 8.28950500e+00, -8.35065126e-01, -1.72617722e+00, ...,\n",
       "         -1.17554379e+00, -1.68649578e+00, -1.68605506e+00],\n",
       "        ...,\n",
       "        [ 7.68629456e+00, -2.07709298e-01, -1.63052976e+00, ...,\n",
       "         -1.22133493e+00, -1.59922671e+00, -1.72817969e+00],\n",
       "        [ 7.64861155e+00, -1.81433603e-01, -1.63532877e+00, ...,\n",
       "         -1.21184826e+00, -1.59582126e+00, -1.72168493e+00],\n",
       "        [ 7.76042795e+00, -2.71064639e-01, -1.67773449e+00, ...,\n",
       "         -1.21912742e+00, -1.56093216e+00, -1.74837685e+00]]],\n",
       "      dtype=float32), label_ids=array([[-1,  0,  1, ..., -1, -1, -1],\n",
       "       [-1,  0,  0, ..., -1, -1, -1],\n",
       "       [-1,  1,  0, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [-1,  0,  0, ..., -1, -1, -1],\n",
       "       [-1,  0,  0, ..., -1, -1, -1],\n",
       "       [-1,  0,  0, ..., -1, -1, -1]]), metrics={'test_loss': 0.5235235095024109, 'test_precision': 0.6054130967889872, 'test_recall': 0.1857517474398962, 'test_micro-f1': 0.2842773414039949, 'test_runtime': 13.5616, 'test_samples_per_second': 159.126, 'test_steps_per_second': 9.955})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (EvalPrediction, IntervalStrategy, Trainer,\n",
    "                          TrainingArguments, set_seed)\n",
    "\n",
    "from eval import absa_evaluate\n",
    "from model import BertForTokenClassification\n",
    "from optimization import BertAdam, WarmupLinearSchedule\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=7)\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    pred_Y, gold_Y = id2label(predictions, labels)\n",
    "    p, r, f1 = absa_evaluate(pred_Y, gold_Y)\n",
    "    return {\"precision\": p, \"recall\": r, \"micro-f1\": f1}\n",
    "param_optimizer = [(k, v) for k, v in model.named_parameters() if v.requires_grad == True]\n",
    "param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=IntervalStrategy.EPOCH, report_to='all', num_train_epochs=3)\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
    "        'weight_decay': 0.01\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "        'weight_decay': 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def create_optimizer_and_scheduler(self, num_training_steps: int):\n",
    "        self.optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                            lr=3e-5,\n",
    "                            warmup=0.1,\n",
    "                            t_total=num_training_steps)\n",
    "        self.create_scheduler(num_training_steps=num_training_steps, optimizer=self.optimizer)\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.predict(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('bert-uda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "46584de9a9b251d8d6a655ff083342365ea615e0ad7e079b39b92660ec098dd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
